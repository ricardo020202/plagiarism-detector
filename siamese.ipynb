{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bb8de6",
   "metadata": {},
   "source": [
    "<h1>Use siamese GNN to predict the similarity of two source codes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cac99c",
   "metadata": {},
   "source": [
    "<h3>Import dependencies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4390b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_java as ts_java\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool, GINConv\n",
    "import torch.nn.functional as F, torch.nn as nn\n",
    "from torch_geometric.data import Batch\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "67737eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all seeds to make results reproducible.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d8a2e",
   "metadata": {},
   "source": [
    "<h2>Data preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b41d0",
   "metadata": {},
   "source": [
    "<h3>Define constants</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dad6d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_directory1 = './datasets/conplag_preprocessed'\n",
    "java_directory2 = './datasets/ir_plag_preprocessed'\n",
    "java_LANGUAGE = Language(ts_java.language())\n",
    "parser = Parser(java_LANGUAGE)\n",
    "csv_paths = ['./labels/conplag-labels.csv', './labels/ir_plag_labels.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6b312cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93039af9",
   "metadata": {},
   "source": [
    "<h3>Get AST</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3185acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_java_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf8') as file:\n",
    "        code = file.read()\n",
    "\n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    def traverse(node, parent_idx=None):\n",
    "        idx = len(nodes)\n",
    "        nodes.append(node.type)\n",
    "        \n",
    "        if parent_idx is not None:\n",
    "            edges.append((parent_idx, idx))\n",
    "        \n",
    "        for child in node.children:\n",
    "            traverse(child, idx)\n",
    "\n",
    "    traverse(root_node)\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f384178",
   "metadata": {},
   "source": [
    "<h3>Build data for GNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3b169cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_vocab(java_directories, file_lists):\n",
    "    all_node_types = set()\n",
    "\n",
    "    for java_directory, file_list in zip(java_directories, file_lists):\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(java_directory, file_name)\n",
    "            nodes, _ = parse_java_file(file_path)\n",
    "            all_node_types.update(nodes)\n",
    "\n",
    "    node_type_to_idx = {typ: idx for idx, typ in enumerate(sorted(all_node_types))}\n",
    "    return node_type_to_idx\n",
    "\n",
    "def create_node_features(nodes, node_type_to_idx):\n",
    "    node_features = [node_type_to_idx[typ] for typ in nodes]\n",
    "    return node_features\n",
    "\n",
    "def create_graph_data(nodes, edges, node_features, embedding_layer):\n",
    "    x = embedding_layer(torch.tensor(node_features))\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9ee31811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_node_types, embedding_dim):\n",
    "        super(NodeEmbeddingLayer, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_node_types, embedding_dim)\n",
    "\n",
    "    def forward(self, node_indices):\n",
    "        return self.embeddings(node_indices)\n",
    "    \n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7ae20970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_pairs(pairs_df, java_directory, node_type_to_idx, embedding_layer):\n",
    "    data_pairs = []\n",
    "    for idx, row in pairs_df.iterrows():\n",
    "        file1, file2, label = row['id1'], row['id2'], row['plagio']\n",
    "\n",
    "        file1_path = os.path.join(java_directory, file1)\n",
    "        file2_path = os.path.join(java_directory, file2)\n",
    "\n",
    "        nodes1, edges1 = parse_java_file(file1_path)\n",
    "        nodes2, edges2 = parse_java_file(file2_path)\n",
    "\n",
    "        node_features1 = create_node_features(nodes1, node_type_to_idx)\n",
    "        node_features2 = create_node_features(nodes2, node_type_to_idx)\n",
    "\n",
    "        data1 = create_graph_data(nodes1, edges1, node_features1, embedding_layer)\n",
    "        data2 = create_graph_data(nodes2, edges2, node_features2, embedding_layer)\n",
    "\n",
    "        data_pairs.append((data1, data2, label))\n",
    "        \n",
    "    return data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c7ddf221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n",
      "Number of pairs in training dataset: 842\n",
      "Number of pairs in validation set: 133\n",
      "Number of pairs in test set: 267\n",
      "Dataset 1 - First pair:\n",
      "  Graph 1: 919 nodes, 918 edges\n",
      "  Graph 2: 1246 nodes, 1245 edges\n",
      "  Label: 0\n",
      "Dataset 2 - First pair:\n",
      "  Graph 1: 108 nodes, 107 edges\n",
      "  Graph 2: 109 nodes, 108 edges\n",
      "  Label: 1\n"
     ]
    }
   ],
   "source": [
    "pairs_df1 = load_csv(csv_paths[0])\n",
    "pairs_df2 = load_csv(csv_paths[1])\n",
    "\n",
    "file_list1 = list(set(pairs_df1['id1'].tolist() + pairs_df1['id2'].tolist()))\n",
    "file_list2 = list(set(pairs_df2['id1'].tolist() + pairs_df2['id2'].tolist()))\n",
    "\n",
    "java_directories = [java_directory1, java_directory2]\n",
    "file_lists = [file_list1, file_list2]\n",
    "\n",
    "node_type_to_idx = build_global_vocab(java_directories, file_lists)\n",
    "embedding_layer = NodeEmbeddingLayer(len(node_type_to_idx), embedding_dim)\n",
    "\n",
    "data_pairs1 = prepare_data_for_pairs(pairs_df1, java_directory1, node_type_to_idx, embedding_layer)\n",
    "data_pairs2 = prepare_data_for_pairs(pairs_df2, java_directory2, node_type_to_idx, embedding_layer)\n",
    "\n",
    "all_pairs = data_pairs1 + data_pairs2\n",
    "random.shuffle(all_pairs)\n",
    "\n",
    "test_size = int(len(all_pairs) * 0.2)\n",
    "val_size = int(len(all_pairs) * 0.1)\n",
    "\n",
    "test_pairs = all_pairs[:test_size]\n",
    "val_pairs = all_pairs[test_size:test_size+val_size]\n",
    "train_pairs = all_pairs[test_size+val_size:]\n",
    "\n",
    "plagiarism_pairs = [pair for pair in train_pairs if pair[2] == 1]\n",
    "non_plagiarism_pairs = [pair for pair in train_pairs if pair[2] == 0]\n",
    "\n",
    "if len(plagiarism_pairs) > len(non_plagiarism_pairs):\n",
    "    plagiarism_pairs = random.sample(plagiarism_pairs, len(non_plagiarism_pairs))\n",
    "else:\n",
    "    non_plagiarism_pairs = random.sample(non_plagiarism_pairs, len(plagiarism_pairs))\n",
    "\n",
    "balanced_train_pairs = plagiarism_pairs + non_plagiarism_pairs\n",
    "random.shuffle(balanced_train_pairs)\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "print(f\"Number of pairs in training dataset: {len(balanced_train_pairs)}\")\n",
    "print(f\"Number of pairs in validation set: {len(val_pairs)}\")\n",
    "print(f\"Number of pairs in test set: {len(test_pairs)}\")\n",
    "data1, data2, label1 = data_pairs1[0]\n",
    "data3, data4, label2 = data_pairs2[0]\n",
    "print(f\"Dataset 1 - First pair:\")\n",
    "print(f\"  Graph 1: {data1.num_nodes} nodes, {data1.num_edges} edges\")\n",
    "print(f\"  Graph 2: {data2.num_nodes} nodes, {data2.num_edges} edges\")\n",
    "print(f\"  Label: {label1}\")\n",
    "print(f\"Dataset 2 - First pair:\")\n",
    "print(f\"  Graph 1: {data3.num_nodes} nodes, {data3.num_edges} edges\")\n",
    "print(f\"  Graph 2: {data4.num_nodes} nodes, {data4.num_edges} edges\")\n",
    "print(f\"  Label: {label2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b01de",
   "metadata": {},
   "source": [
    "<h2>Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdc33d",
   "metadata": {},
   "source": [
    "<h3>Build GNN siamese architecture</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9c79f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GNNEncoder(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "#         super(GNNEncoder, self).__init__()\n",
    "#         self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "#         self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "#     def forward(self, x, edge_index, batch):\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = global_mean_pool(x, batch)\n",
    "#         return x\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        nn1 = nn.Sequential(nn.Linear(in_channels, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        nn2 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, out_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        nn3 = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, out_dim))\n",
    "        self.conv3 = GINConv(nn3)\n",
    "        nn4 = nn.Sequential(nn.Linear(out_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim))\n",
    "        self.conv4 = GINConv(nn4)\n",
    "        nn5 = nn.Sequential(nn.Linear(out_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim))\n",
    "        self.conv5 = GINConv(nn5)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(out_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv5(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SiameseNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.encoder = GNNEncoder(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        h1 = self.encoder(data1.x, data1.edge_index, data1.batch)\n",
    "        h2 = self.encoder(data2.x, data2.edge_index, data2.batch)\n",
    "        return h1, h2\n",
    "\n",
    "def contrastive_loss(h1, h2, label, margin=1.0):\n",
    "    distance = F.pairwise_distance(h1, h2)\n",
    "    loss = (label * torch.pow(distance, 2) + \n",
    "           (1 - label) * torch.pow(F.relu(margin - distance), 2))\n",
    "    return loss.mean()\n",
    "\n",
    "def collate_fn(pairs, device):\n",
    "    data1_list, data2_list, labels = [], [], []\n",
    "    for d1, d2, label in pairs:\n",
    "        data1_list.append(d1)\n",
    "        data2_list.append(d2)\n",
    "        labels.append(label)\n",
    "\n",
    "    batch1 = Batch.from_data_list(data1_list).to(device)\n",
    "    batch2 = Batch.from_data_list(data2_list).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.float, device=device).to(device)\n",
    "\n",
    "    return batch1, batch2, labels\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Cuántas épocas esperar después de la última mejora.\n",
    "            min_delta (float): Mínima mejora en la métrica para ser considerada como mejora.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                print(f\"Early stopping triggered after {self.patience} epochs without improvement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a974c0",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f8dc2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_pairs, val_pairs, device, scheduler, threshold, epochs=50, batch_size=32):\n",
    "    set_seed(42)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    best_threshold = threshold\n",
    "    patience = 10\n",
    "    counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        random.Random(42 + epoch).shuffle(train_pairs)\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i in range(0, len(train_pairs), batch_size):\n",
    "            batch_pairs = train_pairs[i:i+batch_size]\n",
    "            batch1, batch2, labels = collate_fn(batch_pairs, device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            h1, h2 = model(batch1, batch2)\n",
    "            \n",
    "            distances = F.pairwise_distance(h1, h2)\n",
    "            loss = contrastive_loss(h1, h2, labels)\n",
    "            \n",
    "            loss.backward(retain_graph=True)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * len(batch_pairs)\n",
    "            \n",
    "            predictions = (distances < best_threshold).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_loss = total_loss / len(train_pairs)\n",
    "        train_accuracy = correct / total if total > 0 else 0\n",
    "        \n",
    "        val_loss, val_accuracy = evaluate(model, val_pairs, device, best_threshold, batch_size)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} Train Loss: {train_loss:.4f}, Accuracy: {train_accuracy*100:.2f}% Val Loss: {val_loss:.4f}, Accuracy: {val_accuracy*100:.2f}%\")\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            new_threshold, _ = find_best_threshold(model, val_pairs, device, batch_size=batch_size)\n",
    "            print(f\"Updated threshold: {new_threshold:.4f}\")\n",
    "            best_threshold = new_threshold\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                'epoch': epoch,\n",
    "                'threshold': best_threshold,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy': val_accuracy\n",
    "            }\n",
    "            torch.save(checkpoint, f'./models/siamese_gnn_model_epoch_{epoch+1}.pth')\n",
    "            print(f\"Saved best model at epoch {epoch+1} with threshold {best_threshold:.4f}\")\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            \n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return best_threshold, train_losses, val_losses, train_accs, val_accs\n",
    "\n",
    "def evaluate(model, data_pairs, device, threshold, batch_size=32):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_pairs), batch_size):\n",
    "            batch_pairs = data_pairs[i:i+batch_size]\n",
    "            batch1, batch2, labels = collate_fn(batch_pairs, device)\n",
    "            \n",
    "            h1, h2 = model(batch1, batch2)\n",
    "            loss = contrastive_loss(h1, h2, labels)\n",
    "            \n",
    "            total_loss += loss.item() * len(batch_pairs)\n",
    "            \n",
    "            distances = F.pairwise_distance(h1, h2)\n",
    "            predictions = (distances < threshold).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(data_pairs)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def find_best_threshold(model, dataset, device, batch_size=32, thresholds=np.linspace(0, 2, 100)):\n",
    "    model.eval()\n",
    "    all_preds_raw = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            batch_pairs = dataset[i:i+batch_size]\n",
    "\n",
    "            batch1, batch2, labels = collate_fn(batch_pairs, device)\n",
    "\n",
    "            h1, h2 = model(batch1, batch2)\n",
    "\n",
    "            distances = F.pairwise_distance(h1, h2)\n",
    "            all_preds_raw.extend(distances.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds_raw = np.array(all_preds_raw)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    best_threshold = None\n",
    "    best_f1 = -1\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        preds = (all_preds_raw < threshold).astype(int)\n",
    "        f1 = f1_score(all_labels, preds)\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f03c5028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1e399511",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 32\n",
    "out_dim = 32\n",
    "threshold = 0.2626\n",
    "epochs = 200\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b45679b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 Train Loss: 0.4332, Accuracy: 50.12% Val Loss: 0.5066, Accuracy: 47.37%\n",
      "Saved best model at epoch 1 with threshold 0.2626\n",
      "Epoch 2/200 Train Loss: 0.3389, Accuracy: 51.43% Val Loss: 0.3330, Accuracy: 64.66%\n",
      "Saved best model at epoch 2 with threshold 0.2626\n",
      "Epoch 3/200 Train Loss: 0.3092, Accuracy: 51.43% Val Loss: 0.3152, Accuracy: 67.67%\n",
      "Saved best model at epoch 3 with threshold 0.2626\n",
      "Epoch 4/200 Train Loss: 0.2970, Accuracy: 52.97% Val Loss: 0.3204, Accuracy: 64.66%\n",
      "Epoch 5/200 Train Loss: 0.2962, Accuracy: 54.51% Val Loss: 0.2953, Accuracy: 71.43%\n",
      "Updated threshold: 0.2020\n",
      "Saved best model at epoch 5 with threshold 0.2020\n",
      "Epoch 6/200 Train Loss: 0.2845, Accuracy: 49.41% Val Loss: 0.2870, Accuracy: 73.68%\n",
      "Saved best model at epoch 6 with threshold 0.2020\n",
      "Epoch 7/200 Train Loss: 0.2767, Accuracy: 50.59% Val Loss: 0.3036, Accuracy: 72.93%\n",
      "Epoch 8/200 Train Loss: 0.2542, Accuracy: 53.92% Val Loss: 0.2717, Accuracy: 73.68%\n",
      "Saved best model at epoch 8 with threshold 0.2020\n",
      "Epoch 9/200 Train Loss: 0.2561, Accuracy: 53.92% Val Loss: 0.2632, Accuracy: 73.68%\n",
      "Saved best model at epoch 9 with threshold 0.2020\n",
      "Epoch 10/200 Train Loss: 0.2578, Accuracy: 54.04% Val Loss: 0.2754, Accuracy: 73.68%\n",
      "Updated threshold: 0.1616\n",
      "Epoch 11/200 Train Loss: 0.2556, Accuracy: 54.87% Val Loss: 0.2625, Accuracy: 75.94%\n",
      "Saved best model at epoch 11 with threshold 0.1616\n",
      "Epoch 12/200 Train Loss: 0.2501, Accuracy: 54.99% Val Loss: 0.2593, Accuracy: 75.19%\n",
      "Saved best model at epoch 12 with threshold 0.1616\n",
      "Epoch 13/200 Train Loss: 0.2380, Accuracy: 55.94% Val Loss: 0.2609, Accuracy: 76.69%\n",
      "Epoch 14/200 Train Loss: 0.2483, Accuracy: 56.65% Val Loss: 0.2627, Accuracy: 78.20%\n",
      "Epoch 15/200 Train Loss: 0.2390, Accuracy: 55.82% Val Loss: 0.2357, Accuracy: 76.69%\n",
      "Updated threshold: 0.3030\n",
      "Saved best model at epoch 15 with threshold 0.3030\n",
      "Epoch 16/200 Train Loss: 0.2446, Accuracy: 62.47% Val Loss: 0.2523, Accuracy: 72.18%\n",
      "Epoch 17/200 Train Loss: 0.2409, Accuracy: 62.71% Val Loss: 0.2296, Accuracy: 75.94%\n",
      "Saved best model at epoch 17 with threshold 0.3030\n",
      "Epoch 18/200 Train Loss: 0.2287, Accuracy: 64.01% Val Loss: 0.2183, Accuracy: 76.69%\n",
      "Saved best model at epoch 18 with threshold 0.3030\n",
      "Epoch 19/200 Train Loss: 0.2123, Accuracy: 66.15% Val Loss: 0.1982, Accuracy: 81.20%\n",
      "Saved best model at epoch 19 with threshold 0.3030\n",
      "Epoch 20/200 Train Loss: 0.2195, Accuracy: 64.49% Val Loss: 0.2225, Accuracy: 78.20%\n",
      "Updated threshold: 0.2222\n",
      "Epoch 21/200 Train Loss: 0.2103, Accuracy: 63.90% Val Loss: 0.1969, Accuracy: 78.20%\n",
      "Saved best model at epoch 21 with threshold 0.2222\n",
      "Epoch 22/200 Train Loss: 0.2217, Accuracy: 62.35% Val Loss: 0.2145, Accuracy: 83.46%\n",
      "Epoch 23/200 Train Loss: 0.2114, Accuracy: 63.54% Val Loss: 0.1803, Accuracy: 81.95%\n",
      "Saved best model at epoch 23 with threshold 0.2222\n",
      "Epoch 24/200 Train Loss: 0.2219, Accuracy: 58.31% Val Loss: 0.1923, Accuracy: 80.45%\n",
      "Epoch 25/200 Train Loss: 0.2091, Accuracy: 63.42% Val Loss: 0.2061, Accuracy: 81.95%\n",
      "Updated threshold: 0.2424\n",
      "Epoch 26/200 Train Loss: 0.2087, Accuracy: 64.25% Val Loss: 0.1865, Accuracy: 81.95%\n",
      "Epoch 27/200 Train Loss: 0.2153, Accuracy: 64.73% Val Loss: 0.2000, Accuracy: 82.71%\n",
      "Epoch 28/200 Train Loss: 0.2060, Accuracy: 62.59% Val Loss: 0.2007, Accuracy: 81.20%\n",
      "Epoch 29/200 Train Loss: 0.2028, Accuracy: 64.96% Val Loss: 0.1804, Accuracy: 81.20%\n",
      "Epoch 30/200 Train Loss: 0.2032, Accuracy: 63.54% Val Loss: 0.1987, Accuracy: 79.70%\n",
      "Updated threshold: 0.2222\n",
      "Epoch 31/200 Train Loss: 0.2049, Accuracy: 66.27% Val Loss: 0.2136, Accuracy: 81.95%\n",
      "Epoch 32/200 Train Loss: 0.2014, Accuracy: 64.85% Val Loss: 0.1921, Accuracy: 81.20%\n",
      "Epoch 33/200 Train Loss: 0.2024, Accuracy: 64.01% Val Loss: 0.1919, Accuracy: 80.45%\n",
      "Early stopping at epoch 33\n"
     ]
    }
   ],
   "source": [
    "model = SiameseNetwork(\n",
    "    in_channels=embedding_dim,\n",
    "    hidden_channels=hidden_dim,\n",
    "    out_channels=out_dim\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "best_threshold, train_losses, val_losses, train_accs, val_accs = train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    balanced_train_pairs,\n",
    "    val_pairs,\n",
    "    device,\n",
    "    scheduler,\n",
    "    threshold=threshold,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4ca0a",
   "metadata": {},
   "source": [
    "<h3>Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "02f098f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_metadata(model_path, in_channels, hidden_dim, out_dim, device):\n",
    "    loaded_model = SiameseNetwork(\n",
    "        in_channels=in_channels,\n",
    "        hidden_channels=hidden_dim,\n",
    "        out_channels=out_dim\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    threshold = checkpoint.get('threshold', 0.5)\n",
    "    epoch = checkpoint.get('epoch', 0)\n",
    "    val_loss = checkpoint.get('val_loss', 0)\n",
    "    val_accuracy = checkpoint.get('val_accuracy', 0)\n",
    "    \n",
    "    print(f\"Loaded model from {model_path}\")\n",
    "    print(f\"Model was saved at epoch {epoch+1} with validation loss {val_loss:.4f} and accuracy {val_accuracy*100:.2f}%\")\n",
    "    print(f\"Using threshold: {threshold:.4f}\")\n",
    "    \n",
    "    return loaded_model, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8f09c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ./models/siamese_gnn_model_epoch_23.pth\n",
      "Model was saved at epoch 23 with validation loss 0.1803 and accuracy 81.95%\n",
      "Using threshold: 0.2222\n"
     ]
    }
   ],
   "source": [
    "loaded_model, best_threshold = load_model_with_metadata('./models/siamese_gnn_model_epoch_23.pth', embedding_dim, hidden_dim, out_dim, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2067fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(model, dataset, device, batch_size=batch_size, threshold=threshold):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            batch_pairs = dataset[i:i+batch_size]\n",
    "\n",
    "            batch1, batch2, labels = collate_fn(batch_pairs, device)\n",
    "\n",
    "            h1, h2 = model(batch1, batch2)\n",
    "\n",
    "            distances = F.pairwise_distance(h1, h2)\n",
    "            predictions = (distances < threshold).float()\n",
    "\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = [int(round(x)) for x in all_preds]\n",
    "    all_labels = [int(round(x)) for x in all_labels]\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[1, 0])\n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(cm, labels):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    plt.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + labels)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "\n",
    "    for (i, j), value in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f'{value}', ha='center', va='center', color='white' if cm[i, j] > cm.max()/2 else 'black')\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f0edce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.8358\n"
     ]
    }
   ],
   "source": [
    "_, best_f1 = find_best_threshold(loaded_model, val_pairs, device, batch_size=batch_size, thresholds=np.linspace(0, 2, 100))\n",
    "print(f\"Best F1 score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6428e1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos con plagio (1): 110\n",
      "Ejemplos sin plagio (0): 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricor\\AppData\\Local\\Temp\\ipykernel_289432\\1322368525.py:30: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels([''] + labels)\n",
      "C:\\Users\\ricor\\AppData\\Local\\Temp\\ipykernel_289432\\1322368525.py:31: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_yticklabels([''] + labels)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_plagio = sum(1 for _, _, label in test_pairs if label == 1)\n",
    "num_no_plagio = sum(1 for _, _, label in test_pairs if label == 0)\n",
    "\n",
    "print(f\"Ejemplos con plagio (1): {num_plagio}\")\n",
    "print(f\"Ejemplos sin plagio (0): {num_no_plagio}\")\n",
    "\n",
    "cm = compute_confusion_matrix(loaded_model, test_pairs, device, batch_size=batch_size, threshold=best_threshold)\n",
    "plot_confusion_matrix(cm, labels=['Plagiarized', 'Not Plagiarized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f54be710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2556, Test Accuracy: 78.28%\n"
     ]
    }
   ],
   "source": [
    "avg_loss, accuracy = evaluate(loaded_model, test_pairs, device, best_threshold, batch_size=batch_size)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
