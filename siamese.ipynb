{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4bb8de6",
   "metadata": {},
   "source": [
    "<h1>Use siamese GNN to predict the similarity of two source codes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cac99c",
   "metadata": {},
   "source": [
    "<h3>Import dependencies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4390b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_java as ts_java\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F, torch.nn as nn\n",
    "from torch_geometric.data import Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d8a2e",
   "metadata": {},
   "source": [
    "<h2>Data preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b41d0",
   "metadata": {},
   "source": [
    "<h3>Define constants</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "dad6d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "java_directory1 = './datasets/fire14-source-code-training-dataset/java'\n",
    "java_directory2 = './datasets/ir_plag_preprocessed'\n",
    "java_LANGUAGE = Language(ts_java.language())\n",
    "parser = Parser(java_LANGUAGE)\n",
    "csv_paths = ['./labels/fire14-labels.csv', './labels/ir_plag_labels.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6b312cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93039af9",
   "metadata": {},
   "source": [
    "<h3>Get AST</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "3185acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_java_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf8') as file:\n",
    "        code = file.read()\n",
    "\n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "\n",
    "    nodes = []\n",
    "    edges = []\n",
    "\n",
    "    def traverse(node, parent_idx=None):\n",
    "        idx = len(nodes)\n",
    "        nodes.append(node.type)\n",
    "        \n",
    "        if parent_idx is not None:\n",
    "            edges.append((parent_idx, idx))\n",
    "        \n",
    "        for child in node.children:\n",
    "            traverse(child, idx)\n",
    "\n",
    "    traverse(root_node)\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f384178",
   "metadata": {},
   "source": [
    "<h3>Build data for GNN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3b169cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_global_vocab(java_directories, file_lists):\n",
    "    all_node_types = set()\n",
    "\n",
    "    for java_directory, file_list in zip(java_directories, file_lists):\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(java_directory, file_name)\n",
    "            nodes, _ = parse_java_file(file_path)\n",
    "            all_node_types.update(nodes)\n",
    "\n",
    "    node_type_to_idx = {typ: idx for idx, typ in enumerate(sorted(all_node_types))}\n",
    "    return node_type_to_idx\n",
    "\n",
    "\n",
    "\n",
    "def create_node_features(nodes, node_type_to_idx):\n",
    "    node_features = [node_type_to_idx[typ] for typ in nodes]\n",
    "    return node_features\n",
    "\n",
    "def create_graph_data(nodes, edges, node_features, embedding_layer):\n",
    "    x = embedding_layer(torch.tensor(node_features))\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "9ee31811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_node_types, embedding_dim):\n",
    "        super(NodeEmbeddingLayer, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_node_types, embedding_dim)\n",
    "\n",
    "    def forward(self, node_indices):\n",
    "        return self.embeddings(node_indices)\n",
    "    \n",
    "embedding_dim = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7ae20970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_pairs(pairs_df, java_directory, node_type_to_idx, embedding_layer):\n",
    "    data_pairs = []\n",
    "    for idx, row in pairs_df.iterrows():\n",
    "        file1, file2, label = row['id1'], row['id2'], row['plagio']\n",
    "\n",
    "        file1_path = os.path.join(java_directory, file1)\n",
    "        file2_path = os.path.join(java_directory, file2)\n",
    "\n",
    "        nodes1, edges1 = parse_java_file(file1_path)\n",
    "        nodes2, edges2 = parse_java_file(file2_path)\n",
    "\n",
    "        node_features1 = create_node_features(nodes1, node_type_to_idx)\n",
    "        node_features2 = create_node_features(nodes2, node_type_to_idx)\n",
    "\n",
    "        data1 = create_graph_data(nodes1, edges1, node_features1, embedding_layer)\n",
    "        data2 = create_graph_data(nodes2, edges2, node_features2, embedding_layer)\n",
    "\n",
    "        data_pairs.append((data1, data2, label))\n",
    "        \n",
    "    return data_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c7ddf221",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df1 = load_csv(csv_paths[0])\n",
    "pairs_df2 = load_csv(csv_paths[1])\n",
    "\n",
    "file_list1 = list(set(pairs_df1['id1'].tolist() + pairs_df1['id2'].tolist()))\n",
    "file_list2 = list(set(pairs_df2['id1'].tolist() + pairs_df2['id2'].tolist()))\n",
    "\n",
    "java_directories = [java_directory1, java_directory2]\n",
    "file_lists = [file_list1, file_list2]\n",
    "\n",
    "node_type_to_idx = build_global_vocab(java_directories, file_lists)\n",
    "embedding_layer = NodeEmbeddingLayer(len(node_type_to_idx), embedding_dim)\n",
    "\n",
    "data_pairs1 = prepare_data_for_pairs(pairs_df1, java_directory1, node_type_to_idx, embedding_layer)\n",
    "data_pairs2 = prepare_data_for_pairs(pairs_df2, java_directory2, node_type_to_idx, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "efd9de80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n",
      "Number of pairs in dataset 1: 504\n",
      "Number of pairs in dataset 2: 460\n",
      "Dataset 1 - First pair:\n",
      "  Graph 1: 2068 nodes, 2067 edges\n",
      "  Graph 2: 619 nodes, 618 edges\n",
      "  Label: 0\n",
      "Dataset 2 - First pair:\n",
      "  Graph 1: 108 nodes, 107 edges\n",
      "  Graph 2: 109 nodes, 108 edges\n",
      "  Label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Data preparation complete.\")\n",
    "print(f\"Number of pairs in dataset 1: {len(data_pairs1)}\")\n",
    "print(f\"Number of pairs in dataset 2: {len(data_pairs2)}\")\n",
    "\n",
    "data1, data2, label1 = data_pairs1[0]\n",
    "data3, data4, label2 = data_pairs2[0]\n",
    "\n",
    "print(f\"Dataset 1 - First pair:\")\n",
    "print(f\"  Graph 1: {data1.num_nodes} nodes, {data1.num_edges} edges\")\n",
    "print(f\"  Graph 2: {data2.num_nodes} nodes, {data2.num_edges} edges\")\n",
    "print(f\"  Label: {label1}\")\n",
    "\n",
    "print(f\"Dataset 2 - First pair:\")\n",
    "print(f\"  Graph 1: {data3.num_nodes} nodes, {data3.num_edges} edges\")\n",
    "print(f\"  Graph 2: {data4.num_nodes} nodes, {data4.num_edges} edges\")\n",
    "print(f\"  Label: {label2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5b01de",
   "metadata": {},
   "source": [
    "<h2>Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdc33d",
   "metadata": {},
   "source": [
    "<h3>Build GNN siamese architecture</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "9c79f1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x\n",
    "\n",
    "class SiameseNetwork(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.encoder = GNNEncoder(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        h1 = self.encoder(data1.x, data1.edge_index, data1.batch)\n",
    "        h2 = self.encoder(data2.x, data2.edge_index, data2.batch)\n",
    "        return h1, h2\n",
    "\n",
    "def contrastive_loss(h1, h2, label, margin=1.0):\n",
    "    distance = F.pairwise_distance(h1, h2)\n",
    "    loss = (label * torch.pow(distance, 2) + \n",
    "           (1 - label) * torch.pow(F.relu(margin - distance), 2))\n",
    "    return loss.mean()\n",
    "\n",
    "def collate_fn(pairs, device):\n",
    "    data1_list, data2_list, labels = [], [], []\n",
    "    for d1, d2, label in pairs:\n",
    "        data1_list.append(d1)\n",
    "        data2_list.append(d2)\n",
    "        labels.append(label)\n",
    "\n",
    "    batch1 = Batch.from_data_list(data1_list).to(device)\n",
    "    batch2 = Batch.from_data_list(data2_list).to(device)\n",
    "    labels = torch.tensor(labels, dtype=torch.float, device=device).to(device)\n",
    "\n",
    "    return batch1, batch2, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a974c0",
   "metadata": {},
   "source": [
    "<h3>Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f8dc2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_pairs, device, epochs=10, batch_size=32, threshold=1.0):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i in range(0, len(data_pairs), batch_size):\n",
    "            batch_pairs = data_pairs[i:i+batch_size]\n",
    "\n",
    "            batch1, batch2, labels = collate_fn(batch_pairs, device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            h1, h2 = model(batch1, batch2)\n",
    "            loss = contrastive_loss(h1, h2, labels)\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            distances = F.pairwise_distance(h1, h2)\n",
    "            predictions = (distances < threshold).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f03c5028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b45679b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 8.2825, Accuracy: 19.25%\n",
      "Epoch 2, Loss: 4.6771, Accuracy: 33.93%\n",
      "Epoch 3, Loss: 3.6900, Accuracy: 50.40%\n",
      "Epoch 4, Loss: 3.3347, Accuracy: 58.53%\n",
      "Epoch 5, Loss: 3.0904, Accuracy: 60.91%\n",
      "Epoch 6, Loss: 2.8860, Accuracy: 61.90%\n",
      "Epoch 7, Loss: 2.7075, Accuracy: 63.49%\n",
      "Epoch 8, Loss: 2.5509, Accuracy: 63.89%\n",
      "Epoch 9, Loss: 2.4139, Accuracy: 64.48%\n",
      "Epoch 10, Loss: 2.2965, Accuracy: 65.48%\n",
      "Epoch 11, Loss: 2.1975, Accuracy: 66.27%\n",
      "Epoch 12, Loss: 2.1141, Accuracy: 66.87%\n",
      "Epoch 13, Loss: 2.0437, Accuracy: 67.46%\n",
      "Epoch 14, Loss: 1.9829, Accuracy: 68.65%\n",
      "Epoch 15, Loss: 1.9292, Accuracy: 68.65%\n",
      "Epoch 16, Loss: 1.8808, Accuracy: 69.25%\n",
      "Epoch 17, Loss: 1.8360, Accuracy: 69.44%\n",
      "Epoch 18, Loss: 1.7950, Accuracy: 70.24%\n",
      "Epoch 19, Loss: 1.7567, Accuracy: 70.44%\n",
      "Epoch 20, Loss: 1.7215, Accuracy: 70.63%\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "hidden_dim = 32\n",
    "out_dim = 32\n",
    "\n",
    "model = SiameseNetwork(\n",
    "    in_channels=embedding_dim,\n",
    "    hidden_channels=hidden_dim,\n",
    "    out_channels=out_dim\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model, optimizer, data_pairs1, device, epochs=20, batch_size=16)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), './models/siamese_gnn_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
